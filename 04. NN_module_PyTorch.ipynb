{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Plan of action\n",
        "\n",
        "* Instead of doing manually we will use NN module for forward pass.\n",
        "* We will use built in loss funtion.\n",
        "* Using NN module for sigmoid function.\n",
        "* For optimization we will be using optimizer."
      ],
      "metadata": {
        "id": "zxUVpCuRQv5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The nn module\n",
        "\n",
        "The torch.nn module in PyTorch is a core library that provides a wide array of classes and\n",
        "functions designed to help developers build neural networks efficiently and effectively. It\n",
        "abstracts the complexity of creating and training neural networks by offering pre-built layers,\n",
        "loss functions, activation functions, and other utilities, enabling you to focus on designing and\n",
        "experimenting with model architectures.\n",
        "\n",
        "Key Components of torch.nn:\n",
        "1. Modules (Layers):\n",
        "* nn.Module: The base class for all neural network modules. Your custom models and layers should subclass this class.\n",
        "* Common Layers: Includes layers like nn.Linear (fully connected layer), nn.Conv2d (convolutional layer), nn.LSTM (recurrent layer), and many others.\n",
        "\n",
        "2. Activation Functions:\n",
        "* Functions like nn.ReLU, nn.Sigmoid, and nn.Tanh introduce non-linearities to the model, allowing it to learn complex patterns.\n",
        "\n",
        "3. Loss Functions:\n",
        "* Provides loss functions such as nn.CrossEntropyLoss, nn.MSELoss, and nn.NLLLoss to quantify the difference between the model's predictions and the actual targets.\n",
        "\n",
        "4. Container Modules:\n",
        "* nn.Sequential: A sequential container to stack layers in order.\n",
        "\n",
        "5. Regularization and Dropout:\n",
        "* Layers like nn.Dropout and nn.BatchNorm2d help prevent overfitting and improve the model's ability to generalize to new data."
      ],
      "metadata": {
        "id": "aJqK0YEle1tV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B67Jqv_TfRgW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Use super().__init__() in PyTorch?\n",
        "1. Properly Initializes the Base Class (nn.Module)\n",
        "\n",
        "* PyTorch’s nn.Module is the base class that provides all the essential machinery for neural networks, like tracking parameters, registering submodules, and enabling features such as .to(), .cuda(), and saving/loading models.\n",
        "\n",
        "* When you call super().__init__(), you’re making sure that all this important setup in nn.Module happens for your model. If you skip this step, your model won’t work correctly-parameters might not be registered, and PyTorch features could break.\n",
        "\n",
        "2. Follows Object-Oriented Programming Principles\n",
        "\n",
        "* In Python, when you create a class that inherits from another class, you should always call the parent’s __init__ method to ensure everything is set up properly. super() is the standard way to do this"
      ],
      "metadata": {
        "id": "CFVd1hwrh3Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model(nn.Module):\n",
        "\n",
        "  def __init__(self, num_feature):\n",
        "\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_feature, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "\n",
        "    out = self.linear(features)\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "OOMhdn2OgLqJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset\n",
        "features = torch.rand(10,5)\n",
        "\n",
        "# Create model\n",
        "model = model(features.shape[1])\n",
        "\n",
        "# Call model for forward pass.\n",
        "model(features)        # model.forward(features)  --> You can also use that, but pytorch prefers other way."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYrgjzgCikvI",
        "outputId": "f52ab2ed-dd14-4af6-80b6-99d3a77f10e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5729],\n",
              "        [0.6366],\n",
              "        [0.6105],\n",
              "        [0.5662],\n",
              "        [0.5553],\n",
              "        [0.5540],\n",
              "        [0.5654],\n",
              "        [0.5748],\n",
              "        [0.5885],\n",
              "        [0.5966]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XXQtDqejUqk",
        "outputId": "25104d65-349e-434e-ce38-32a37fb16572"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1301,  0.1736,  0.0012,  0.0909,  0.0549]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.linear.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRTIayRRjgCA",
        "outputId": "2330f0f7-db97-49b6-a461-6e80f97a6dc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.2783], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIu9yStajnEa",
        "outputId": "c54cb7f1-be5b-4977-f75b-a841a00fed83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeXoGOV1j5Ma",
        "outputId": "6e17dbef-ff2e-40b3-8eb3-0b4afbef1256"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "model                                    [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 1]                   6\n",
              "├─Sigmoid: 1-2                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 6\n",
              "Trainable params: 6\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a NN with a hidder layer.\n",
        "\n",
        "* 1st layer 3 nodes. --> relu activation function.\n",
        "* 2nd layer 1 nodes. --> sigmoid activation function."
      ],
      "metadata": {
        "id": "OeIvo0dHkNSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model1(nn.Module):\n",
        "\n",
        "  def __init__(self, num_feature):\n",
        "\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(num_feature, 3)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.layer2 = nn.Linear(3, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, features):\n",
        "\n",
        "    out = self.layer1(features)\n",
        "    out = self.relu(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "3ie6fzY4kAYf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model1(features.shape[1])\n",
        "\n",
        "model(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRuov6fcmFwk",
        "outputId": "87703d13-938b-46c7-9653-f60b1d81db87"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4213],\n",
              "        [0.4830],\n",
              "        [0.4714],\n",
              "        [0.4100],\n",
              "        [0.4149],\n",
              "        [0.4050],\n",
              "        [0.4092],\n",
              "        [0.4198],\n",
              "        [0.4274],\n",
              "        [0.4398]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5QEmYglmVAN",
        "outputId": "fa042155-ddd5-4793-87f3-cd3703eaf391"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.4308, -0.2790, -0.1598,  0.0133, -0.0993],\n",
              "        [-0.4236,  0.1339,  0.2033, -0.3611, -0.3679],\n",
              "        [-0.1159, -0.1987,  0.2981,  0.0021,  0.0996]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layer1.bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS5NbEGMnQeU",
        "outputId": "12feae4d-907a-43b9-b20c-d3ca93f17e73"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([ 0.4050, -0.0512,  0.1821], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, input_size=features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBWkNQL8nSII",
        "outputId": "11d3869a-a627-4730-b0bf-d39a62eb5abb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "model1                                   [10, 1]                   --\n",
              "├─Linear: 1-1                            [10, 3]                   18\n",
              "├─ReLU: 1-2                              [10, 3]                   --\n",
              "├─Linear: 1-3                            [10, 1]                   4\n",
              "├─Sigmoid: 1-4                           [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 22\n",
              "Trainable params: 22\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential container.\n",
        "\n",
        "Why We Need nn.Sequential\n",
        "1. Simplifies Model Definition\n",
        "\n",
        "* Instead of writing a custom class and manually defining the forward() method, you can stack layers in the order you want them to run. PyTorch will automatically connect the output of one layer to the input of the next.\n",
        "\n",
        "2. Treats the Whole Sequence as a Single Module\n",
        "\n",
        "* The entire sequence of layers acts as one module. This means you can easily move it to a device (like GPU), save/load it, or use it as a part of a bigger model"
      ],
      "metadata": {
        "id": "rmDMm_nznsr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class model2(nn.Module):\n",
        "\n",
        "  def __init__(self, num_feature):\n",
        "\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_feature, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, features):\n",
        "    out = self.network(features)\n",
        "    return out"
      ],
      "metadata": {
        "id": "6VVs9oeZnccL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.rand(10,5)\n",
        "print(features.shape[1])\n",
        "model2 = model2(5)\n",
        "\n",
        "model2(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFvnlxofpZQH",
        "outputId": "82607a8c-3ddc-4f64-d8d8-bb07b7a89781"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4456],\n",
              "        [0.4888],\n",
              "        [0.4039],\n",
              "        [0.4899],\n",
              "        [0.4565],\n",
              "        [0.4632],\n",
              "        [0.4253],\n",
              "        [0.4690],\n",
              "        [0.4308],\n",
              "        [0.4709]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3BOpKhYpcnR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}